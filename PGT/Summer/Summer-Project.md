# Project

## Introduction

- Unit Director: Peter Bennet
- Assessment: 100% coursework (Assessed slightly differently depending on whether you take the group or individual project option)
- Credit points: 60

### Principles and Design

The summer project is the culmination of your studies. This is your chance to demonstrate what you’ve learned and put your skills on display. 
It is designed to complement the goals of your taught units, exercising all of the professional, conceptual, and technical skills you have 
developed throughout the course. This, of course, implies challenges, but the result is always something you, as a student, and we, 
as a Department, can be proud of. From an academic perspective several core principles act as a guide:

**Engagement in self-directed, independent work:** You (as a team, if you participate in the group project, or as an individual if you pursue 
an individual project) are responsible for every aspect of the project. Numerous sources of support and advice are clearly available, but you 
should take ultimate ownership of the project and therefore drive its organisation and delivery. This aspect can be both challenging and 
exciting. On one hand, you must cope with this responsibility. On the other, it allows a level of freedom that doesn’t exist elsewhere in 
the course. 

**In-depth investigation of topics with significant challenge:** Our expectation is that MSc projects will focus on a topic with some 
challenge: the topic will ideally capture a focused set of problems or objectives, whose difficulty and value are carefully identified and 
clearly articulated. Projects are typically distinguished by this requirement, the depth (and sometimes volume) of resulting work, and also by 
added emphasis on higher-level understanding and critical analysis. However, it remains important that the type of challenge can legitimately 
differ between project topics: this fact stems naturally from the vast diversity within Computer Science as a subject. Our goal is to recognise 
and support this diversity while still rewarding higher-quality work (of whatever type) with higher marks.

### Group vs Individual projects  
Head to one of the following links for more information about each path.  
[Group Projects](https://cs-uob.github.io/PGT/Summer/group)  
[Individual Projects](https://cs-uob.github.io/PGT/Summer/individual)  

#### Ethical Approval

Depending on the type of project and evaluation you are conducting, you may not need to make a full application to the Faculty Ethics Research 
Committee (FREC). All projects fall into one of three categories: projects which do not require ethical review at all, projects which can be reviewed 
by your supervisor, and projects which require full ethical review by the FREC. (This process has itself been reviewed by the FREC, as ethics application 
0028.)

**Projects not requiring ethical review**  
A project does not require ethical review only if it does not involve gathering data from human or animal participants, either directly or indirectly. 
This means, for example, the author cannot conduct surveys, they cannot ask other people to test software, and they cannot take pictures or video that 
contain people. Two examples of projects that would not require ethical review are as follows:
- Jean is doing a project in graph theory studying snarks. This will involve reviewing the literature and perhaps proving theoretical results or writing 
some code to generate snarks. The only experiments Jean will run involve testing and profiling her own code.
- Adam is doing a project in machine learning, and he is attempting to train a neural network to recognise different art styles and periods. In doing so, 
he will use a large data set of public domain images downloaded from the Internet, and perhaps one or two photos of his own pieces. 

**Projects covered by blanket ethics approval**   
This category covers projects which involve gathering data only from humans (not from animals) and only under the following circumstances:
- The project does not gather data from a vulnerable population, such as people affected by illness or economic disadvantage, children under 18 years of 
age, or people recruited from self-help groups. 
- The project does not gather data about: racial or ethnic origin, religious or similar beliefs, membership of a trade union, physical or mental health, 
sexual activities, criminal history, drug use, or other obviously sensitive information.
- All data is anonymous at collection, so that if the data were to be lost there would be no realistic prospect of the participants being identified. In 
particular, the project does not take photos, videos, or audio recordings of people, and it does not ask about names, addressed, postcodes, phone numbers, 
email addresses, physical features, or social media handles.
- Before any data is gathered from a participant, they give full informed consent. That is, they understand what data will be collected and what the data will 
be used for, and they give and explicit verbal or written statement to this effect. In particular, if part of the data comes from observation, then 
participants are told what will be recorded before they start.
- No participants are tricked or deceived in any way, for example by being given false feedback about their performance at a task or being misled about the 
focus of the study.
- If the participants are asked to perform a task, then this task involves no danger of physical or mental harm. For example, the project does not ask 
participants to sprint or to view distressing images.

Three examples of projects that would fall into this category are:
- Ayodya is writing a computer game for her project. As part of refining the core gameplay loop, she wants to get feedback from new players. She asks a few of 
her friends to play the game as she watches and takes notes. Afterwards, she asks them a few questions about the game. She is careful to tell them in advance 
that she’ll be observing them.
- Tan is writing a piece of software for research into grumkins for his project. Since Bristol researchers specialise mostly in writing snarks, he posts to a 
forum for grumkin researchers explaining his situation, asking what they would like out of a grumkin verifier and noting that any replies may be incorporated 
into his project. He then uses the requirements to decide what features to develop, and later releases the software as open source. When writing up his project, 
he removes all forum names from the feedback before including it. 
- Mohammed is testing the effectiveness of a new user-interface element as part of an HCI project. To do so, he codes two versions of a user interface, one 
using the new element and one using a more traditional design. He divides participants into two groups, one for each version. He tells each group he is 
interested in testing the effectiveness of the user interface of the software and asks them to carry out a task while he watches and takes notes.

If you think your project falls into this category, you should confirm this with your supervisor before you start gathering data. The two of you will then need 
to fill out a very short form available from the unit Blackboard page, and you will need to add a note to your report’s frontmatter.

**Projects requiring ethical review by the FREC**  
All other projects fall into this category. Four examples are:
- Chris is doing an HCI project to study effective survey design. They ask people to fill out one of two randomly chosen versions of an online survey about 
their favourite types of pizza. The two surveys are identical except that at the end, both versions ask for participants’ email addresses in different ways; 
Chris is interested in which survey design gets more people to give their email addresses. The email addresses are discarded on collection to avoid gathering 
personal data. This would still require a full ethics application, since they are deceiving participants about the purpose of the study.
- Alan is doing a cybersecurity project on the information inadvertently leaked via Bluetooth from peoples’ personal devices. He puts up a sign in the MVB atrium 
explaining that an experiment is happening, then sits there with a device gathering leaked data. He reads through it to remove anything potentially identifying, 
then includes it in his project. This would require a full ethics application, since it involves gathering data from participants who have not given full 
informed consent.
- Reut suffers from clinical depression, and for her project she is writing a mobile app to help fellow sufferers track their moods. When she has finished codding 
the app, she posts a link to Big White Wall (an anonymous support forum) asking for feedback. This would require a full ethics application, since it involves 
asking about mental health and gathering data from a vulnerable population.
- Johannes is doing a computer vision project in which he attempts to train a computer to recognise numbers on signs. As part of his test data, he walks through the 
department and takes photos of all the office doors. This would require a full ethics application, since it involves gathering information (namely, office numbers) 
from participants without their consent.

If your project is in this category, don’t panic! The next step is to make a formal Stage 1 ethics application to the FREC through the [OREMS tool](https://orems.bristol.ac.uk/ActivityForm/Index). The application process is not hard. It involves filling out a short online form. You should also attach a 
Participant Information Sheet (PIS) and consent form, at minimum. The committee may ask for you to include additional documents as necessary. Typically if a 
problem is “obviously harmless,” albeit not covered by the blanket ethics application, then it will be approved. That said, you must make your application well 
in advance, as delays of three weeks or more are relatively common, and you will not be granted an extension if this stops you from completing your project before 
the due date. If your application is approved, then you will need to add a sentence to your front matter quoting the application number. If the FREC identifies 
significant causes for concern, then they may ask you to make a Stage 2 ethics application. This is a more difficult affair, and if it happens then you should 
think carefully about whether your planned experiments are crucial to the project. 


## Marking

Each project is assessed by two Markers, one of whom is the project Supervisor. The Supervisor acts as a topic-specific expert who assesses the project on 
scientific rigour, and the second Marker may be a non-expert who provides an external perspective. In what follows, the Supervisor and the second Marker 
are together referred to as the marking panel. 
The overarching goals of the marking panel are to: 
1. follow the assessment process and criteria outlined below as transparently as possible; 
2. produce a robust mark for the project, suitable for use in ranking projects across the year and paying close attention to the classification boundaries; 
3. ensure the mark is fair and consistent when compared to other projects within the cohort; and 
4. minimise bias caused by over- or under-enthusiastic Supervisors and/or Markers. 

### The Assessment Process

Barring minor deviations (e.g., due to deadline extensions or mitigating circumstances), the intended assessment process is as follows: 
1. The Markers assigned to a given project inspect the associated deliverables closely, particularly the dissertation, and attend the relevant presentations. 
They each independently use the marking criteria detailed in Appendices A and B to arrive at an initial mark on the University’s 0–100 scale, supported by a 
written justification. 
2. The two Markers then exchange their marks and justifications and agree on a single consolidated mark. Differences in initial marks are to be expected and 
usually arise from a different weighting of factors contributing to the mark, rather than outright disagreement. Importantly, the markers do not simply average 
their two marks, but instead discuss the merits and failings of the project with respect to the marking criteria. If they are unable to agree on a mark, they 
may involve a third Marker. 
3. Once they have agreed a consolidated mark, the Markers produce written feedback for the student by merging and editing their original written assessments. 
They also produce a written explanation of how they arrived at the consolidated mark for the benefit of the Unit Director and the External Examiner (see below). 
The supervisor is responsible for finalising the agreed feedback. 
4. Once all marks are available, the Unit Director provides oversight of the marking process by checking all marks and feedback for consistency and, if 
necessary, proposing minor adjustments to specific Markers. 
5. As with all units within the Department, the unit marks and assessment process itself are then checked by the External Examiner, who will be a senior 
member of staff from another University. As part of the process of checking quality and fairness, they will inspect (a sample of) project deliverables; they 
may additionally viva (a sample of) students to check whether our assessment matches their own. 

### Plagiarism Checks

Checking for plagiarism is a difficult challenge, especially when a Marker is unfamiliar with the associated topic. A centralised, consistent approach is 
therefore applied to ensure as fair an outcome to the assessment process as possible: 
- The marking panel marks each project as normal, i.e., assuming there is no issue with plagiarism, but noting specific concerns as and when applicable.
- As early as possible after their electronic submission via Blackboard, the Unit Director uses the TurnItIn system to check all dissertations, then later 
collates any specific concerns identified by the Markers. 
- Any cases that warrant further investigation and/or penalty are then passed to and managed by a separate Departmental process. 

### Assessment Criteria

From both the student and staff perspectives, it is important to have a clear set of criteria to which the assessment process can refer. Such criteria 
are notoriously hard to construct: the diversity of project topics inevitably produces exceptions to any set of criteria, no matter how seemingly perfect. 
Our attempt at a set of criteria valid for most projects is given in Appendices A (for enterprise-type projects) and B (for research-type projects). For 
each mark range, we outline characteristics that we might expect projects in that range to exhibit.  
It is very important to note that most projects in a given mark range will not exhibit every characteristic we list – generally they will be better in some 
aspects and worse in others. The final mark should be based on the project as a whole, not on any single characteristic. That said, for a project to be 
awarded a given grade class, it should usually match the described characteristics in that range (or above) in most respects. For example, a project with 
roughly half its criteria in the 50–59 range, roughly half its criteria in the 60–69 range, and one or two in the 70–79 range should be awarded a 2.ii, not 
a 2.i or a 1st.   
As a general rule of thumb: 
- A project should get marks in the 80–100 range (i.e. a high First) if it is outstanding work. Most enterprise-type projects in this range should have 
produced a useful product likely to gain popularity outside the university; most research-type projects in this range should have produced either a novel 
piece of research suitable for academic publication or a piece of exposition that will be a useful reference even for established academics. We expect that 
in most years, a small proportion of projects earning Firsts will fall into this range. 
- A project should get marks in the 70–79 range (i.e. a First) if it is very good work. An enterprise-type project in this range should demonstrate that the 
student is a viable candidate for a good software development job, and a research-type project in this range should demonstrate that the student is a viable 
candidate for a good industrial research job or PhD position. We expect in most years, about 30-40% of projects will earn Firsts (in line with the BSc project 
unit).  
- A project should get marks in the 60–69 range (i.e. a 2.i) if it is good work but not exceptional. An enterprise-type project in this range should 
demonstrate that the student is capable of working in the industry, and a research-type project in this range should demonstrate that the student has a solid 
grasp of the subject. We expect that in most years, about 35-45% of projects will earn 2.is (again in line with the BSc project unit). 
- A project should get marks in the 50–59 range (i.e. a 2.ii) if it is mediocre work, or if it is good work marred by serious flaws (such as a major hole in 
a proof, a serious defect in an experimental procedure, or a piece of software that is not useful to its target audience due to a failure to gather stakeholder 
requirements). We expect that in most years, all but a small proportion of projects will earn a 2.ii or above. 
- A project should get marks in the 40–49 range (i.e. a 3rd) if it is poor work but has some redeeming features. Examples might include an otherwise-acceptable 
project which is of a length and scope more appropriate for a one- or two-week coursework project, or an overambitious enterprise project where the student had 
some promising ideas but failed to implement them in any meaningful way. 
- A project should get marks in the 0–39 range (i.e. a fail) if it contains little to nothing of value.

## Common Pitfalls

**Over- or under-ambition in project topic or execution plan:** An ideal project is typically a careful balance between less ambitious goals, which are clearly 
achievable, and more ambitious goals, which will be difficult to achieve and which therefore carry a greater risk of failure. Too few of the former 
(over-ambition) can lead to a project that fails to achieve its goals and doesn’t get anywhere. Too few of the latter (under-ambition) can lead to a project 
which succeeds at its goals but doesn’t contribute anything of value. In either case, the possible marks will be limited.

**Poor time management:** Time management is hard, and procrastination is tempting when the deadline is so far away. However, having a solid time plan in place 
and making slow, steady progress will go a long way to ensuring the success of your project as a whole. There is no substitute for being able to take the time 
to properly think through a problem rather than grabbing the first available solution, or for being able to go back and revise an assumption which has proved 
unproductive.Conversely, don’t work too hard! You can think of working late nights as borrowing from the future at a highly punitive interest rate - it might 
help initially but in the long run you’ll be a lot less productive than you would have if you’d worked at a slower and more even pace. Everyone is different, 
but as a general rule treating your dissertation like a full-time job (40 hours/week) can lead to a better project as well as ensuring you don’t completely 
exhaust yourself working odd or overly long hours.

**Failure to account for required time for writing:** One of the most common failure modes is not putting aside enough time to write your dissertation. Parts 
of this will often have to be left until close to the deadline, since they will be hard or impossible to write until you have done the associated work. On the 
other hand, if you leave all of it until close to the deadline, you will probably end up with a rushed mess that earns a low mark. Often, it makes sense to write 
incrementally throughout the project duration and to focus on writing up the work you’ve already done before expanding it further. If the cost of including an 
extra experiment in your dissertation is that your dissertation as a whole is poorly written, it will have cost you marks rather than gained you marks.

**Poor contingency planning:** Any serious project management includes some form of risk assessment, complete with contingency plans for likely issues. You don’t 
have to write this up formally, but you do have to think about it, or your entire project could come crashing down around you. Most obviously: use current 
anti-virus software and back up your work regularly, including an off-site backup in case of fire! (GitHub and Overleaf are your friends!) You will not be granted 
an extension due to data loss, and the penalties for late submission are severe. Less obvious risks, which still occur more often than you might expect, include:
- Inability to access vital equipment due to it breaking, not having permission, or the university not having it available;
- Prolonged inability to contact your supervisor(s) and/or advisor(s), e.g. due to a holiday or severe illness on their part;
- Finding out that a dataset that you were planning to use doesn’t exist or isn’t available anymore;
- Finding out two weeks before the project deadline that your code will need three weeks to run;
- Needing to perform behavioural testing for an enterprise project, but failing to find enough test subjects.
As an example, if the vital equipment from the first bullet point were a sensor required to capture data for later processing, a good first step would be to source 
both a main sensor and backup sensor early in the project, and possibly also to set up the processing step to accept synthetic data as an additional fallback.

**Lack of contact with supervisor(s) and/or advisor(s):** For topic-specific advice, your supervisor should be your first point of contact for the entire duration 
of the project. History suggests that regular meetings with your supervisor are a strong indicator of a successful project. Such meetings do not have to be 
lengthy (a five-minute progress check in which you say “I am working on X but have not finished it” is fine), but without them you can easily find yourself 
spending weeks on something which is either a dead end or which will add very little value to your project. 

**Failure to write comprehensibly:** Over the course of writing the dissertation, you will inevitably become more and more familiar with the area you are working 
in, and the things you once considered difficult will seem simple. It is surprisingly easy to forget that you ever found them difficult, and to assume that they 
will be easy for a reader as well. This is emphatically not the case, especially if they don’t have a background in the topic already (which may well be the case 
with one of your markers). Avoid words like “obviously” and “clearly” in your dissertation - things may be neither obvious nor clear. Always try to remember that 
the person you’re writing for has not spent hundreds of hours researching the topic and will not know as much as you do. A useful technique to avoid this trap is 
to keep a working set of notes as you go (remembering your learning process can help you guide the reader through it as well).

**Overwriting instead of versioning:** More often than you’d think, a method you tried but decided against, or a section you wrote but discarded will be useful 
at some point in the future, perhaps in a different part of your project. If you never saved this method or section, however, you’ll have to do the whole thing 
from scratch again. Version control is your friend, for both your code and your report. Never assume that something you’ve written is useless. That useless code 
will come back to haunt you in a few weeks when it’s the perfect solution to another problem but you never saved it. 
